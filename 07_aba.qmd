---
title: "Area-based Approach"
---

```{r setup, include=FALSE}
source("R/setup_rgl.R")
```

## Relevant Resources

-   [Code](https://github.com/liamirwin/SL25_lidRtutorial/blob/main/R/07_aba.R)
-   [lidRbook section](https://r-lidar.github.io/lidRbook/modelling.html)

## Overview

The `area-based approach` (ABA) is a widely-used method for estimating forest attributes, such as timber volume and biomass, by combining field measurements with wall-to-wall lidar data.

Here we will demonstrate a typical implementation of the `area-based approach` (ABA) for forest attribute estimation using lidar data and ground plot measurements.

## Environment

```{r clear warnings, warnings = FALSE, message=FALSE}
# Clear environment
rm(list = ls(globalenv()))

# Load packages
library(lidR)
library(sf)
library(terra)
library(dplyr)
```

## Key References
-   [Best Practices for Forest ABA - White et al. 2013](https://publications.gc.ca/collections/collection_2013/rncan-nrcan/Fo148-1-10-eng.pdf)

-   [ABA Model Development Guide - White et al. 2017](https://publications.gc.ca/collections/collection_2018/rncan-nrcan/Fo148-1-18-eng.pdf)

-   [Structurally Guided Sampling with sgsR](https://tgoodbody.github.io/sgsR/)

`ABA` takes lidar point cloud metrics and connects them (through regression) to forest (or other ecosystem) attributes typically measured on the ground in field plots. This now fundamental approach was originally presented by [Nasset 2002](https://doi.org/10.1016/S0034-4257(01)00290-5 "Predicting forest stand characteristics with airborne scanning laser using a practical two-stage procedure and field data - Remote Sensing of Environment 2002").

`ABA` generally use coregistered plots (measured with GNSS coordinates) as samples to build models to estimate field measured attributes across wall-to-wall coverages of lidar `pixel_metrics`.

In doing so we can apply models to lidar derived metric rasters over wider coverages to create estimate maps of key *forest inventory variables* such as stem volume, basal area, and stem density.

```{r, include = FALSE}
#| label: fig-white2013-knitr
#| fig-cap: "ABA workflow - Figure 4 in White et al. 2013."
#| fig-alt: "A diagram showing the area-based approach workflow."
#| fig-align: "center"

knitr::include_graphics("img/white2013_fig4.png")
```


## Ground Plot Data

Today we will work will a series of fixed radius (11.28 m) circular plots (n = 162), measured across Forêt Montmorency during 2015 and 2016.

At each of these locations a 400 m2 circular area was established in the field, each tree (above a certain size threshold) was measured and the tree list was processed into metrics describing the `merchantable stem volume`, `stem density`, and `basal area` using regional equations.

Today we will perform the steps necessary to integrate these plot measurements together with coincident ALS data into an area-based prediction of field measured attributes across the wider ALS coverage.

We will focus on the processing of the lidar dataset, and present some very simple model development steps, for more detail on model development and prediction see [White 2017](https://publications.gc.ca/collections/collection_2018/rncan-nrcan/Fo148-1-18-eng.pdf).

## Plot Level lidar Metrics

### Option 1: Integrated `plot_metrics` function

```{r plot_metrics, warning=FALSE, message=FALSE}
# Read in plot centres
plots <- st_read("data/plots/ctg_plots.gpkg", quiet = TRUE) 

# Read in catalog of normalized LAZ tiles
ctg <- catalog("data/ctg_norm")
plot(st_geometry(ctg@data))
plot(st_geometry(plots ), add = TRUE, col = "red")

# Calculate with all-in-one plot_metrics function
plot_mets <- plot_metrics(las = ctg, # use the catalog of normalized LAZ files
                          func = .stdmetrics, # use standard list of metrics
                          geometry = plots, # use plot centres
                          radius = 11.28 # define the radius of the circular plots
                          )

# Select subset of metrics from the resulting dataframe for model development
plot_mets <- dplyr::select(plot_mets,
                    c(plot_id, ba_ha, sph_ha, # forest attributes
                      merch_vol_ha, zq95, pzabove2, zskew # lidar metrics
                      ))

plot_mets
```

### Option 2: `clip_roi` and `catalog_apply`

While the `plot_metrics` function is efficient, you may want more control over the process or wish to save the point clouds for each plot for further analysis. The following code demonstrates a more manual workflow. First, we will clip the lidar point clouds using the plot boundaries and save each clipped plot as a separate `.laz` file. We then create a new `catalog` of these individual plot point clouds and use `catalog_apply` to calculate standard metrics for each point cloud.

Now we will clip the circular plots, save them as `.laz` files, and treat them as a catalog of independent lidar files to calculate a table of metrics.

```{r clip_plots}
# Clip normalized LAZ files for each plot location
opt_output_files(ctg) <- "data/plots/las/{plot_id}"
opt_laz_compression(ctg) <- TRUE
# Create circular polygons of 11.28m radius (400m2 area)
plot_buffer <- st_buffer(plots, 11.28)
# Clip normalized LAZ file for each plot
clip_roi(ctg, plot_buffer)
```

This resulting folder of individual plot `.laz` files can now be treated as a catalog of independent files to generate a table of metrics.

```{r clip_plot_metrics}
# Create a new catalog referencing the clipped plots we saved
ctg_plot <- catalog("data/plots/las")
opt_independent_files(ctg_plot) <- TRUE # process each plot independently

# Define a metrics function to apply to plots
generate_plot_metrics <- function(chunk){
  # Check if tile is empty
  las <- readLAS(chunk)                  
  if (is.empty(las)) return(NULL)
  # Calculate standard list of metrics (56) built in to lidR for each point cloud
  mets <- cloud_metrics(las, .stdmetrics)
  # Convert output metrics to dataframe (from list)
  mets_df <- as.data.frame(mets)
  # Add plot ID to metrics dataframe
  mets_df$plot_id <- gsub(basename(chunk@files),
                          pattern = ".laz",
                          replacement = "")
  return(mets_df)
}

# Apply our function to each plot in the catalog
plot_mets <- catalog_apply(ctg_plot, generate_plot_metrics)

# Bind the output dataframes into one table
plot_df <- do.call(rbind, plot_mets)

# Rejoin the lidar metrics with the plot vector with attributes
plot_sf <- left_join(plots, plot_df, by = "plot_id")

# Select subset of metrics for model development
plot_mets <- dplyr::select(plot_sf,
                    c(plot_id, ba_ha, sph_ha, # forest attributes
                      merch_vol_ha, zq95, pzabove2, zskew # lidar metrics
                      ))

plot_mets
```

What we are left with is a dataframe of plot-level lidar metrics and field measured forest attributes that we can use to develop predictive models for wall-to-wall mapping.

## Applying across Forêt Montmorency

### Plot Network

```{r plot_plotnetwork, echo = FALSE, message = FALSE, warning = FALSE}
library(mapview)

# Read a shapefile representing the boundary
bdy <- st_read("data/fm_boundary.gpkg", quiet = TRUE) #read in the FM boundary
# Read in tile index
ctg_index <- st_read("data/als_index.gpkg", quiet = TRUE)

# Read full set of plot locations
plots <- st_read("data/plots/fm_efi_plots.gpkg", quiet = TRUE)

mapview::mapviewOptions(basemaps = "Esri.WorldImagery")

m <- mapview::mapview(
  ctg_index,
  layer.name = "ALS Tiles",
  alpha.regions = 0.5,
  lwd = 0.5,
  color = "grey"
) +
  mapview::mapview(
    plots,
    layer.name = "Ground Plots",
    col.regions = "red",
    alpha = 0.8
  ) +
  mapview::mapview(
    bdy,
    layer.name = "Forêt Montmorency Boundary",
    col.regions = "blue",
    alpha.regions = 0.2,
    color = "blue",
    lwd = 2,
    alpha = 1.0
  )

m
```


## Model Development

To keep things simple we will use a small set of three lidar metrics that are commonly used in ABA models:
-   `zq95` - 95th percentile of height (canopy height)
-   `pzabove2` - Percentage of points above 2m (canopy cover)
-   `zskew` - Skewness of the height distribution (height variability)

For more information read: [White 2017](https://publications.gc.ca/collections/collection_2018/rncan-nrcan/Fo148-1-18-eng.pdf)

We will generate simple linear models for each of our three forest attributes using these three lidar metrics as predictors and our `r nrow(read.csv("data/plots/plots_all.csv"))` field plots as samples.

```{r, include = FALSE}
#| label: fig-white2017-knitr
#| fig-cap: "Overview of area-based model development from Figure 3 in White et al. 2017"
#| fig-alt: "White et al. 2017 - A model development and application guide for generating an enhanced forest inventory using airborne laser scanning data and an area-based approach"
#| fig-align: "center"

knitr::include_graphics("img/white2017_fig3.png")
```


```{r}
# Read in plot metrics with forest attributes and lidar metrics calculated for all 162 plots
plot_mets <- read.csv("data/plots/plots_all.csv")

# Generate linear models for each forest attribute using three lidar metrics
lm_vol <- lm(merch_vol_ha ~ zq95 + zskew + pzabove2, data = plot_mets)
lm_ba <- lm(ba_ha ~ zq95 + zskew + pzabove2, data = plot_mets)
lm_sph <- lm(sph_ha ~ zq95 + zskew + pzabove2, data = plot_mets)

# Extract model coefficients
vol_cf <- lm_vol$coefficients
ba_cf <- lm_ba$coefficients
sph_cf <- lm_sph$coefficients
```

## Model Deployment

Now that we have our models, we can apply them to wall-to-wall lidar metrics calculated across the entire Forêt Montmorency. These metrics have been pre-computed from the larger ALS catalog coverage of 160,000 hectares in area.

```{r plot_forest_metrics, echo = FALSE, message = FALSE, warning = FALSE}
bdy_met <- rast("data/metrics/fm_mets_20m.tif")

library(tidyterra)
library(ggplot2)
library(patchwork)
p1 <- bdy_met$zq95 %>% autoplot()+ theme_classic() + labs(fill = "95th percentile of height (m)") + theme(legend.position = 'bottom')
p2 <- bdy_met$pzabove2 %>% autoplot() + theme_classic() + labs(fill = "Canopy Cover - Percentage of points above 2m (%)") + theme(legend.position = 'bottom')
p3 <- bdy_met$zskew %>% autoplot()+ theme_classic()+ labs(fill = "Skewness of height distribution") + theme(legend.position = 'bottom')

```


::: {.panel-tabset}
## Canopy Height (zq95)
```{r, echo = FALSE}
#| label: fig-metric-zq95
#| fig-cap: "Wall-to-wall raster of the 95th percentile of height (zq95) calculated at 20m resolution across Forêt Montmorency."
p1
```

## Canopy Cover (pzabove2)
```{r, echo = FALSE}
#| label: fig-metric-pzabove2
#| fig-cap: "Wall-to-wall raster of the percentage of points above 2m (pzabove2) calculated at 20m resolution across Forêt Montmorency."
p2
```

## Variability (zskew)
```{r, echo = FALSE}
#| label: fig-metric-zskew
#| fig-cap: "Wall-to-wall raster of the skewness of the height distribution (zskew) calculated at 20m resolution across Forêt Montmorency."
p3
```

:::

### Applying Models

To apply our models we need to create wrapper functions that take our model coefficients and apply them to our pixel metric raster layers.

We will create functions that follows the standard `lm` formula: y = b0 + b1*x1 + b2*x2 + b3*x3

Where y is the attribute, b0 is the intercept, b1, b2, and b3 are the coefficients

Here we will create three functions, one for each of our forest attributes: `Stem Volume` (m3/ha), `Basal Area` (m2/ha), and `Stem Density` (stems/ha).

```{r}
# Create functions from model coefficients that we can apply to metrics rasters
# Function to predict stem volume
vol_lm_r <- function(zq95,zskew,pzabove2){
  vol_cf["(Intercept)"] + (vol_cf["zq95"] * zq95) + (vol_cf["zskew"] * zskew) + (vol_cf["pzabove2"] * pzabove2)
}
# Function to predict basal area
ba_lm_r <- function(zq95,zskew,pzabove2){
  ba_cf["(Intercept)"] + (ba_cf["zq95"] * zq95) + (ba_cf["zskew"] * zskew) + (ba_cf["pzabove2"] * pzabove2)
}
# Function to predict stem density
sph_lm_r <- function(zq95,zskew,pzabove2){
  sph_cf["(Intercept)"] + (sph_cf["zq95"] * zq95) + (sph_cf["zskew"] * zskew) + (sph_cf["pzabove2"] * pzabove2)
}
```

In this example we will achieve this using the [`terra`](https://rspatial.github.io/terra/) package with the `lapp` function that will apply our function to the wall-to-wall metrics raster to generate maps of our three forest attributes. `lapp` applies a function to each cell of our multi-layer metric raster.

```{r}
# Load the full metrics raster
metrics_rast <- rast("data/metrics/fm_mets_20m.tif")
plot(metrics_rast)
# Apply models to generate wall-to-wall forest attribute estimates
# Merchantable Stem Volume
vol_r <- terra::lapp(metrics_rast, fun = vol_lm_r)
plot(vol_r, main = "Merchantable Stem Volume (m3/ha)")
# Basal Area
ba_r <- terra::lapp(metrics_rast, fun = ba_lm_r)
plot(ba_r, main = "Basal Area (m2/ha)")
# Stem Density
sph_r <- terra::lapp(metrics_rast, fun = sph_lm_r)
plot(sph_r, main = "Stem Density (stems/ha)")
```

## Conclusion

We have demonstrated the area-based approach (ABA) for estimating forest attributes using lidar data and ground plot measurements. By calculating plot-level lidar metrics and developing predictive models, we can generate wall-to-wall maps of key forest inventory variables such as stem volume, basal area, and stem density.

Here we used simple linear models for demonstration purposes, but more advanced modeling techniques can be employed such as random forest models.








